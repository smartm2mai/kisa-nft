{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf2440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from demo.image_similarity_keras.model import SiameseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf727d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 07:52:45.066800: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-01 07:52:45.548980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:5e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"siamese_ConvNext_Large\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ConvNext_Large (KerasLayer)  (None, 1536)             196230336 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " out_emb (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " l2_norm (Lambda)            (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,181,504\n",
      "Trainable params: 951,168\n",
      "Non-trainable params: 196,230,336\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efa0854a4f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "model_path = \"../demo/models/ConvNext_Large_64b_100ep_final\"\n",
    "augmentation_config = \"../demo/configs/default_augmentation.json\"\n",
    "\n",
    "# Load model config\n",
    "with open(os.path.join(model_path, \"configs.json\"), \"r\") as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "    # Convert to Namespace\n",
    "    model_config_ns = argparse.Namespace(**model_config)\n",
    "\n",
    "# Load augmentation config\n",
    "with open(augmentation_config, \"r\") as f:\n",
    "    augmentation_config = json.load(f)\n",
    "\n",
    "# Convert model_config dictionary to a namespace\n",
    "model_config_ns = argparse.Namespace(**model_config)\n",
    "\n",
    "# Get the image_size from model_config or use default value if missing\n",
    "default_image_size = 224\n",
    "image_size = model_config.get('image_size', default_image_size)\n",
    "\n",
    "# Initialize model\n",
    "model = SiameseModel(**model_config)\n",
    "\n",
    "# Build and compile model\n",
    "model.build(False)\n",
    "\n",
    "# Load weights\n",
    "model.model.load_weights(os.path.join(model_path, \"weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4cd5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((224, 224))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19444909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_inference(img_array, model):\n",
    "    return model.predict(tf.expand_dims(img_array, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f406979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(feature1, feature2):\n",
    "    similarity = tf.keras.losses.CosineSimilarity(axis=1)\n",
    "    score = (similarity(feature1, feature2) + 1) / 2.0\n",
    "    return score.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92cea796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img_path1, img_path2, model):\n",
    "    img1_array = preprocess_image(img_path1)\n",
    "    img2_array = preprocess_image(img_path2)\n",
    "\n",
    "    feature1 = get_model_inference(img1_array, model)\n",
    "    feature2 = get_model_inference(img2_array, model)\n",
    "\n",
    "    similarity_score = calculate_similarity(feature1, feature2)\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "925139ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 07:54:01.706205: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n",
      "2023-11-01 07:54:03.107323: I tensorflow/stream_executor/cuda/cuda_blas.cc:1804] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images similarity score: 0.3895\n"
     ]
    }
   ],
   "source": [
    "img1_path = \"path_to_image1.jpg\"\n",
    "img2_path = \"path_to_image2.jpg\"\n",
    "\n",
    "similarity = compare_images(img1_path, img2_path, model)\n",
    "print(f\"Images similarity score: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b228feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
